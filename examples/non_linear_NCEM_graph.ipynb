{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import anndata as ad\n",
    "from gpu_spatial_graph_pipeline.data.utils import transforms\n",
    "from gpu_spatial_graph_pipeline.data.anndata2data import AnnData2DataByCategory\n",
    "from gpu_spatial_graph_pipeline.data.datasets import DatasetHartmann\n",
    "from gpu_spatial_graph_pipeline.models.non_linear_ncem import NonLinearNCEM\n",
    "from gpu_spatial_graph_pipeline.data.datamodule import GraphAnnDataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from raw files\n",
      "registering celldata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sel/mambaforge/envs/pyg/lib/python3.8/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting image-wise celldata\n",
      "adding graph-level covariates\n",
      "Loaded 58 images with complete data from 4 patients over 63747 cells with 36 cell features and 8 distinct celltypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Data(x=[1338, 12], edge_index=[2, 8028], y=[1338, 36]),\n",
       " Data(x=[61, 12], edge_index=[2, 366], y=[61, 36]),\n",
       " Data(x=[1316, 12], edge_index=[2, 7896], y=[1316, 36]),\n",
       " Data(x=[1540, 12], edge_index=[2, 9240], y=[1540, 36]),\n",
       " Data(x=[1822, 12], edge_index=[2, 10932], y=[1822, 36]),\n",
       " Data(x=[863, 12], edge_index=[2, 5178], y=[863, 36]),\n",
       " Data(x=[564, 12], edge_index=[2, 3384], y=[564, 36]),\n",
       " Data(x=[1023, 12], edge_index=[2, 6138], y=[1023, 36]),\n",
       " Data(x=[324, 12], edge_index=[2, 1944], y=[324, 36]),\n",
       " Data(x=[287, 12], edge_index=[2, 1722], y=[287, 36]),\n",
       " Data(x=[636, 12], edge_index=[2, 3816], y=[636, 36]),\n",
       " Data(x=[311, 12], edge_index=[2, 1866], y=[311, 36]),\n",
       " Data(x=[890, 12], edge_index=[2, 5340], y=[890, 36]),\n",
       " Data(x=[1235, 12], edge_index=[2, 7410], y=[1235, 36]),\n",
       " Data(x=[1020, 12], edge_index=[2, 6120], y=[1020, 36]),\n",
       " Data(x=[1241, 12], edge_index=[2, 7446], y=[1241, 36]),\n",
       " Data(x=[1438, 12], edge_index=[2, 8628], y=[1438, 36]),\n",
       " Data(x=[1021, 12], edge_index=[2, 6126], y=[1021, 36]),\n",
       " Data(x=[1632, 12], edge_index=[2, 9792], y=[1632, 36]),\n",
       " Data(x=[780, 12], edge_index=[2, 4680], y=[780, 36]),\n",
       " Data(x=[524, 12], edge_index=[2, 3144], y=[524, 36]),\n",
       " Data(x=[669, 12], edge_index=[2, 4014], y=[669, 36]),\n",
       " Data(x=[768, 12], edge_index=[2, 4608], y=[768, 36]),\n",
       " Data(x=[241, 12], edge_index=[2, 1446], y=[241, 36]),\n",
       " Data(x=[935, 12], edge_index=[2, 5610], y=[935, 36]),\n",
       " Data(x=[347, 12], edge_index=[2, 2082], y=[347, 36]),\n",
       " Data(x=[1499, 12], edge_index=[2, 8994], y=[1499, 36]),\n",
       " Data(x=[601, 12], edge_index=[2, 3606], y=[601, 36]),\n",
       " Data(x=[2268, 12], edge_index=[2, 13608], y=[2268, 36]),\n",
       " Data(x=[1912, 12], edge_index=[2, 11472], y=[1912, 36]),\n",
       " Data(x=[1678, 12], edge_index=[2, 10068], y=[1678, 36]),\n",
       " Data(x=[1025, 12], edge_index=[2, 6150], y=[1025, 36]),\n",
       " Data(x=[1306, 12], edge_index=[2, 7836], y=[1306, 36]),\n",
       " Data(x=[1020, 12], edge_index=[2, 6120], y=[1020, 36]),\n",
       " Data(x=[852, 12], edge_index=[2, 5112], y=[852, 36]),\n",
       " Data(x=[1664, 12], edge_index=[2, 9984], y=[1664, 36]),\n",
       " Data(x=[1698, 12], edge_index=[2, 10188], y=[1698, 36]),\n",
       " Data(x=[1672, 12], edge_index=[2, 10032], y=[1672, 36]),\n",
       " Data(x=[777, 12], edge_index=[2, 4662], y=[777, 36]),\n",
       " Data(x=[556, 12], edge_index=[2, 3336], y=[556, 36]),\n",
       " Data(x=[554, 12], edge_index=[2, 3324], y=[554, 36]),\n",
       " Data(x=[937, 12], edge_index=[2, 5622], y=[937, 36]),\n",
       " Data(x=[1524, 12], edge_index=[2, 9144], y=[1524, 36]),\n",
       " Data(x=[1528, 12], edge_index=[2, 9168], y=[1528, 36]),\n",
       " Data(x=[2100, 12], edge_index=[2, 12600], y=[2100, 36]),\n",
       " Data(x=[721, 12], edge_index=[2, 4326], y=[721, 36]),\n",
       " Data(x=[1395, 12], edge_index=[2, 8370], y=[1395, 36]),\n",
       " Data(x=[611, 12], edge_index=[2, 3666], y=[611, 36]),\n",
       " Data(x=[1872, 12], edge_index=[2, 11232], y=[1872, 36]),\n",
       " Data(x=[1217, 12], edge_index=[2, 7302], y=[1217, 36]),\n",
       " Data(x=[1531, 12], edge_index=[2, 9186], y=[1531, 36]),\n",
       " Data(x=[1927, 12], edge_index=[2, 11562], y=[1927, 36]),\n",
       " Data(x=[690, 12], edge_index=[2, 4140], y=[690, 36]),\n",
       " Data(x=[1706, 12], edge_index=[2, 10236], y=[1706, 36]),\n",
       " Data(x=[1325, 12], edge_index=[2, 7950], y=[1325, 36]),\n",
       " Data(x=[1091, 12], edge_index=[2, 6546], y=[1091, 36]),\n",
       " Data(x=[1046, 12], edge_index=[2, 6276], y=[1046, 36]),\n",
       " Data(x=[618, 12], edge_index=[2, 3708], y=[618, 36])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = {\n",
    "    'x':['obs/Cluster_preprocessed','obs/donor'],\n",
    "    'y':['X']\n",
    "}\n",
    "\n",
    "\n",
    "preprocess = [\n",
    "    lambda x,_: transforms.categorize_obs(x,['donor', 'Cluster_preprocessed', 'point']),\n",
    "]\n",
    "\n",
    "category_to_iterate = 'point'\n",
    "\n",
    "a2d = AnnData2DataByCategory(\n",
    "    fields=fields,\n",
    "    category=category_to_iterate,\n",
    "    preprocess=preprocess,\n",
    "    yields_edge_index=True,\n",
    ")\n",
    "\n",
    "\n",
    "#Mibitof\n",
    "dataset = DatasetHartmann(data_path='./example_data/hartmann/')\n",
    "adatas = list(dataset.img_celldata.values())\n",
    "\n",
    "# Merge the list of adatas and convert some string to categories as they should be\n",
    "adata = ad.concat(adatas)\n",
    "\n",
    "datas = a2d(adata)\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = datas[0].x.shape[1]\n",
    "out_channels = datas[0].y.shape[1]\n",
    "num_features, out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = GraphAnnDataModule(datas=datas, num_workers = 12, batch_size=100,learning_type='node')\n",
    "model = NonLinearNCEM(\n",
    "    in_channels=num_features,\n",
    "    out_channels=out_channels,\n",
    "    encoder_hidden_dims=[16],\n",
    "    decoder_hidden_dims=[16],\n",
    "    latent_dim=14,\n",
    "    lr=0.0001,weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer:pl.Trainer = pl.Trainer(accelerator='gpu' if torch.torch.cuda.is_available() else 'cpu',\n",
    "                                max_epochs=100,log_every_n_steps=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdfdsf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type            | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder       | GNNModel        | 446   \n",
      "1 | decoder_sigma | MLPModel        | 852   \n",
      "2 | decoder_mu    | MLPModel        | 852   \n",
      "3 | loss_module   | GaussianNLLLoss | 0     \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3743b3cba0427388365f4c7a2e14c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3278c0fef3454c088fd0698a650051b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe86fd0d1074550a7dd5dee2e13221b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fda3e318550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sel/mambaforge/envs/pyg/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "IOStream.flush timed out\n",
      "Exception ignored in: <function Socket.__del__ at 0x7fda3d965a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sel/mambaforge/envs/pyg/lib/python3.8/site-packages/zmq/sugar/socket.py\", line 111, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd1cc31cdbc46789337db68eb832632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sel/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tupleBatch' object has no attribute 'stores_as'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(model, datamodule\u001b[39m=\u001b[39;49mdm)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:862\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[39mPerform one evaluation epoch over the test set.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[39mIt's separated from fit to make sure you never run on your test set until you want to.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39m    The length of the list corresponds to the number of test dataloaders used.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\n\u001b[0;32m--> 862\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:909\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tested_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path  \u001b[39m# TODO: remove in v1.8\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[39m# run test\u001b[39;00m\n\u001b[0;32m--> 909\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    911\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    912\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtesting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1105\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39msetup_environment()\n\u001b[1;32m   1103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_setup_hook()  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1447\u001b[0m, in \u001b[0;36mTrainer._call_setup_hook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mpre_setup\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatamodule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1447\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_lightning_datamodule_hook(\u001b[39m\"\u001b[39;49m\u001b[39msetup\u001b[39;49m\u001b[39m\"\u001b[39;49m, stage\u001b[39m=\u001b[39;49mfn)\n\u001b[1;32m   1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n\u001b[1;32m   1449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1569\u001b[0m, in \u001b[0;36mTrainer._call_lightning_datamodule_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[39mif\u001b[39;00m callable(fn):\n\u001b[1;32m   1568\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningDataModule]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1569\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/gpu-spatial-graph-pipeline/src/gpu_spatial_graph_pipeline/data/datamodule.py:108\u001b[0m, in \u001b[0;36mGraphAnnDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graphwise_setup(stage)\n\u001b[1;32m    107\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nodewise_setup(stage)\n",
      "File \u001b[0;32m~/Documents/projects/gpu-spatial-graph-pipeline/src/gpu_spatial_graph_pipeline/data/datamodule.py:53\u001b[0m, in \u001b[0;36mGraphAnnDataModule._nodewise_setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_nodewise_setup\u001b[39m(\u001b[39mself\u001b[39m, stage: Optional[\u001b[39mstr\u001b[39m]):\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m Batch\u001b[39m.\u001b[39;49mfrom_data_list(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m     55\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39m=\u001b[39m RandomNodeSplit(\n\u001b[1;32m     56\u001b[0m         split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_rest\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m         num_val\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnum_nodes \u001b[39m*\u001b[39m \u001b[39m0.1\u001b[39m), \u001b[39m1\u001b[39m),\n\u001b[1;32m     58\u001b[0m         num_test\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnum_nodes \u001b[39m*\u001b[39m \u001b[39m0.05\u001b[39m), \u001b[39m1\u001b[39m),\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/torch_geometric/data/batch.py:68\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     58\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[1;32m     69\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m     70\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[1;32m     71\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     72\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[1;32m     73\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[1;32m     74\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[1;32m     78\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/torch_geometric/data/collate.py:37\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     34\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[1;32m     36\u001b[0m \u001b[39m# Create empty stores:\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m out\u001b[39m.\u001b[39;49mstores_as(data_list[\u001b[39m0\u001b[39m])\n\u001b[1;32m     39\u001b[0m follow_batch \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(follow_batch \u001b[39mor\u001b[39;00m [])\n\u001b[1;32m     40\u001b[0m exclude_keys \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude_keys \u001b[39mor\u001b[39;00m [])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tupleBatch' object has no attribute 'stores_as'"
     ]
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ad.concat(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59191    90de\n",
       "59192    90de\n",
       "59193    90de\n",
       "59194    90de\n",
       "59195    90de\n",
       "         ... \n",
       "18510    90de\n",
       "18511    90de\n",
       "18512    90de\n",
       "18513    90de\n",
       "18514    90de\n",
       "Name: donor, Length: 63747, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.obs.donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View of AnnData object with n_obs × n_vars = 18943 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n",
      "View of AnnData object with n_obs × n_vars = 22224 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n",
      "View of AnnData object with n_obs × n_vars = 5811 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n",
      "View of AnnData object with n_obs × n_vars = 16769 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n"
     ]
    }
   ],
   "source": [
    "cats = x.obs.donor.unique()\n",
    "for cat in cats:\n",
    "    print(x[x.obs.donor == cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59191    90de\n",
       "59192    90de\n",
       "59193    90de\n",
       "59194    90de\n",
       "59195    90de\n",
       "         ... \n",
       "18510    90de\n",
       "18511    90de\n",
       "18512    90de\n",
       "18513    90de\n",
       "18514    90de\n",
       "Name: donor, Length: 63747, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.obs.donor.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pyg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "163d3d0f285585011c53b157ec761685e8fd2fea3691b3cdf426d39f7063e055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
