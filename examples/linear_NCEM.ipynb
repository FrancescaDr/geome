{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from random import choices\n",
    "import pytorch_lightning as pl\n",
    "from typing import Callable, List, Optional, Sequence, Union\n",
    "import squidpy as sq\n",
    "import torch\n",
    "from torch_geometric.loader import RandomNodeSampler\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from anndata import AnnData\n",
    "from utils import adata2data\n",
    "from data.node_datamodule import NodeDataModule\n",
    "from models.graph_embedding import GraphEmbedding\n",
    "from models.non_linear_ncem import NonLinearNCEM\n",
    "from models.linear_ncem import LinearNCEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mibitof\n",
    "adata = sq.datasets.mibitof()\n",
    "#feature_name=adata.obs.keys()[0] #Use for IMC dataset\n",
    "feature_names=['Cluster','batch']\n",
    "num_features=len(set(adata.obs[feature_names]))\n",
    "encoder_hidden_dims=30\n",
    "decoder_hidden_dims=30\n",
    "num_vars=adata.X.shape[1]\n",
    "\n",
    "#IMC\n",
    "# adata = sq.datasets.imc()\n",
    "# feature_name=adata.obs.keys()[0] #Use for IMC dataset\n",
    "# num_features=len(set(adata.obs[feature_name]))\n",
    "# num_vars=adata.X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = NodeDataModule(adata=adata,feature_name=feature_names,adata2data_fn=adata2data, num_workers = 8, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [26472], which does not match the required output shape [3309, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  value = torch.cat(values, dim=cat_dim or 0, out=out)\n",
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [39708], which does not match the required output shape [2, 19854]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  value = torch.cat(values, dim=cat_dim or 0, out=out)\n",
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [119124], which does not match the required output shape [3309, 36]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  value = torch.cat(values, dim=cat_dim or 0, out=out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[3309, 8], edge_index=[2, 19854], y=[3309, 36], batch=[3309], ptr=[4])\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearNCEM(in_channels=num_features,out_channels=num_vars, lr=0.0001,weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "gpu=False\n",
    "if gpu:\n",
    "    trainer:pl.Trainer = pl.Trainer(accelerator='gpu',max_epochs=100,log_every_n_steps=1)\n",
    "else:\n",
    "    trainer:pl.Trainer = pl.Trainer(accelerator='cpu',max_epochs=100,log_every_n_steps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type            | Params\n",
      "------------------------------------------------\n",
      "0 | model_sigma | LinearSpatial   | 324   \n",
      "1 | model_mu    | LinearSpatial   | 324   \n",
      "2 | loss_module | GaussianNLLLoss | 0     \n",
      "------------------------------------------------\n",
      "648       Trainable params\n",
      "0         Non-trainable params\n",
      "648       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:495: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [26472], which does not match the required output shape [3309, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  value = torch.cat(values, dim=cat_dim or 0, out=out)\n",
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [39708], which does not match the required output shape [2, 19854]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  value = torch.cat(values, dim=cat_dim or 0, out=out)\n",
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [119124], which does not match the required output shape [3309, 36]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  value = torch.cat(values, dim=cat_dim or 0, out=out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "tensor([[False,  True, False,  ..., False, False, False],\n",
      "        [False,  True, False,  ..., False, False, False],\n",
      "        [False,  True, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False,  True, False],\n",
      "        [False, False, False,  ..., False,  True,  True]])\n",
      "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([3309, 72])\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_952/2473830478.py\", line 1, in <cell line: 1>\n",
      "    trainer.fit(model,datamodule=dm)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 723, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1345, in _run_train\n",
      "    self._run_sanity_check()\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1413, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 155, in advance\n",
      "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 128, in advance\n",
      "    output = self._evaluation_step(**kwargs)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 226, in _evaluation_step\n",
      "    output = self.trainer._call_strategy_hook(\"validation_step\", *kwargs.values())\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1765, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 344, in validation_step\n",
      "    return self.model.validation_step(*args, **kwargs)\n",
      "  File \"/home/chels/TheisLab/repos/gpu-spatial-graph-pipeline/models/linear_ncem.py\", line 94, in validation_step\n",
      "    mu, sigma = self.forward(batch)\n",
      "  File \"/home/chels/TheisLab/repos/gpu-spatial-graph-pipeline/models/linear_ncem.py\", line 60, in forward\n",
      "    mu = self.model_mu(x, edge_index)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/chels/TheisLab/repos/gpu-spatial-graph-pipeline/models/modules/linear_model.py\", line 91, in forward\n",
      "    return self.linear(Xd)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (3309x72 and 8x36)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1992, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42fc222dfbda169bc18a654c374e8265fec58846589cd1da63abc2a574b12f52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
