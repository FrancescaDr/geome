{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import anndata as ad\n",
    "from gpu_spatial_graph_pipeline.data.utils import transforms\n",
    "from gpu_spatial_graph_pipeline.data.anndata2data import AnnData2DataByCategory\n",
    "from gpu_spatial_graph_pipeline.data.datasets import DatasetHartmann\n",
    "from gpu_spatial_graph_pipeline.models.linear_ncem import LinearNCEM\n",
    "from gpu_spatial_graph_pipeline.data.datamodule import GraphAnnDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from raw files\n",
      "registering celldata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sel/mambaforge/envs/pyg/lib/python3.8/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting image-wise celldata\n",
      "adding graph-level covariates\n",
      "Loaded 58 images with complete data from 4 patients over 63747 cells with 36 cell features and 8 distinct celltypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Data(x=[1338, 88], edge_index=[2, 8028], y=[1338, 36]),\n",
       " Data(x=[61, 88], edge_index=[2, 366], y=[61, 36]),\n",
       " Data(x=[1316, 88], edge_index=[2, 7896], y=[1316, 36]),\n",
       " Data(x=[1540, 88], edge_index=[2, 9240], y=[1540, 36]),\n",
       " Data(x=[1822, 88], edge_index=[2, 10932], y=[1822, 36]),\n",
       " Data(x=[863, 88], edge_index=[2, 5178], y=[863, 36]),\n",
       " Data(x=[564, 88], edge_index=[2, 3384], y=[564, 36]),\n",
       " Data(x=[1023, 88], edge_index=[2, 6138], y=[1023, 36]),\n",
       " Data(x=[324, 88], edge_index=[2, 1944], y=[324, 36]),\n",
       " Data(x=[287, 88], edge_index=[2, 1722], y=[287, 36]),\n",
       " Data(x=[636, 88], edge_index=[2, 3816], y=[636, 36]),\n",
       " Data(x=[311, 88], edge_index=[2, 1866], y=[311, 36]),\n",
       " Data(x=[890, 88], edge_index=[2, 5340], y=[890, 36]),\n",
       " Data(x=[1235, 88], edge_index=[2, 7410], y=[1235, 36]),\n",
       " Data(x=[1020, 88], edge_index=[2, 6120], y=[1020, 36]),\n",
       " Data(x=[1241, 88], edge_index=[2, 7446], y=[1241, 36]),\n",
       " Data(x=[1438, 88], edge_index=[2, 8628], y=[1438, 36]),\n",
       " Data(x=[1021, 88], edge_index=[2, 6126], y=[1021, 36]),\n",
       " Data(x=[1632, 88], edge_index=[2, 9792], y=[1632, 36]),\n",
       " Data(x=[780, 88], edge_index=[2, 4680], y=[780, 36]),\n",
       " Data(x=[524, 88], edge_index=[2, 3144], y=[524, 36]),\n",
       " Data(x=[669, 88], edge_index=[2, 4014], y=[669, 36]),\n",
       " Data(x=[768, 88], edge_index=[2, 4608], y=[768, 36]),\n",
       " Data(x=[241, 88], edge_index=[2, 1446], y=[241, 36]),\n",
       " Data(x=[935, 88], edge_index=[2, 5610], y=[935, 36]),\n",
       " Data(x=[347, 88], edge_index=[2, 2082], y=[347, 36]),\n",
       " Data(x=[1499, 88], edge_index=[2, 8994], y=[1499, 36]),\n",
       " Data(x=[601, 88], edge_index=[2, 3606], y=[601, 36]),\n",
       " Data(x=[2268, 88], edge_index=[2, 13608], y=[2268, 36]),\n",
       " Data(x=[1912, 88], edge_index=[2, 11472], y=[1912, 36]),\n",
       " Data(x=[1678, 88], edge_index=[2, 10068], y=[1678, 36]),\n",
       " Data(x=[1025, 88], edge_index=[2, 6150], y=[1025, 36]),\n",
       " Data(x=[1306, 88], edge_index=[2, 7836], y=[1306, 36]),\n",
       " Data(x=[1020, 88], edge_index=[2, 6120], y=[1020, 36]),\n",
       " Data(x=[852, 88], edge_index=[2, 5112], y=[852, 36]),\n",
       " Data(x=[1664, 88], edge_index=[2, 9984], y=[1664, 36]),\n",
       " Data(x=[1698, 88], edge_index=[2, 10188], y=[1698, 36]),\n",
       " Data(x=[1672, 88], edge_index=[2, 10032], y=[1672, 36]),\n",
       " Data(x=[777, 88], edge_index=[2, 4662], y=[777, 36]),\n",
       " Data(x=[556, 88], edge_index=[2, 3336], y=[556, 36]),\n",
       " Data(x=[554, 88], edge_index=[2, 3324], y=[554, 36]),\n",
       " Data(x=[937, 88], edge_index=[2, 5622], y=[937, 36]),\n",
       " Data(x=[1524, 88], edge_index=[2, 9144], y=[1524, 36]),\n",
       " Data(x=[1528, 88], edge_index=[2, 9168], y=[1528, 36]),\n",
       " Data(x=[2100, 88], edge_index=[2, 12600], y=[2100, 36]),\n",
       " Data(x=[721, 88], edge_index=[2, 4326], y=[721, 36]),\n",
       " Data(x=[1395, 88], edge_index=[2, 8370], y=[1395, 36]),\n",
       " Data(x=[611, 88], edge_index=[2, 3666], y=[611, 36]),\n",
       " Data(x=[1872, 88], edge_index=[2, 11232], y=[1872, 36]),\n",
       " Data(x=[1217, 88], edge_index=[2, 7302], y=[1217, 36]),\n",
       " Data(x=[1531, 88], edge_index=[2, 9186], y=[1531, 36]),\n",
       " Data(x=[1927, 88], edge_index=[2, 11562], y=[1927, 36]),\n",
       " Data(x=[690, 88], edge_index=[2, 4140], y=[690, 36]),\n",
       " Data(x=[1706, 88], edge_index=[2, 10236], y=[1706, 36]),\n",
       " Data(x=[1325, 88], edge_index=[2, 7950], y=[1325, 36]),\n",
       " Data(x=[1091, 88], edge_index=[2, 6546], y=[1091, 36]),\n",
       " Data(x=[1046, 88], edge_index=[2, 6276], y=[1046, 36]),\n",
       " Data(x=[618, 88], edge_index=[2, 3708], y=[618, 36])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = {\n",
    "    'x':['obs/Cluster_preprocessed','obs/donor','obsm/design_matrix'],\n",
    "    'y':['X']\n",
    "}\n",
    "\n",
    "preprocess = [\n",
    "    lambda x,_: transforms.add_design_matrix(x,'obs/Cluster_preprocessed','obs/donor','design_matrix')\n",
    "]\n",
    "\n",
    "category_to_iterate = 'point'\n",
    "\n",
    "a2d = AnnData2DataByCategory(\n",
    "    fields=fields,\n",
    "    category=category_to_iterate,\n",
    "    preprocess=preprocess,\n",
    "    yields_edge_index=True,\n",
    ")\n",
    "\n",
    "#Mibitof\n",
    "dataset = DatasetHartmann(data_path='./example_data/hartmann/')\n",
    "adatas = list(dataset.img_celldata.values())\n",
    "\n",
    "\n",
    "# Merge the list of adatas and convert some string to categories as they should be\n",
    "adata = ad.concat(adatas)\n",
    "to_categorize = ['donor', 'Cluster_preprocessed', 'point']\n",
    "for c in to_categorize:\n",
    "    adata.obs[c] = adata.obs[c].astype('category')\n",
    "\n",
    "datas = a2d(adata)\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = datas[0].x.shape[1]\n",
    "out_channels = datas[0].y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = GraphAnnDataModule(adata=adata, adata2data_fn=a2d, num_workers = 12, batch_size=10,learning_type='graph')\n",
    "model = LinearNCEM(in_channels=num_features,out_channels=out_channels, model_type='nonspatial', lr=0.0001,weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer:pl.Trainer = pl.Trainer(accelerator='gpu' if torch.torch.cuda.is_available() else 'cpu',\n",
    "                                max_epochs=100,log_every_n_steps=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model_sigma | LinearNonSpatial | 3.2 K \n",
      "1 | model_mu    | LinearNonSpatial | 3.2 K \n",
      "2 | loss_module | GaussianNLLLoss  | 0     \n",
      "-------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240bcd67ca9745f29cc6a521ab4f0a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearNCEM' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model,datamodule\u001b[39m=\u001b[39;49mdm)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    731\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    733\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    734\u001b[0m )\n\u001b[0;32m--> 735\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    737\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    738\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1166\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1168\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1252\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1274\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1273\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1276\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1343\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1343\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1347\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    154\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 155\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    157\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:143\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    142\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    144\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:240\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m    the outputs of the step\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 240\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1704\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1704\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1706\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1707\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:370\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[1;32m    369\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/gpu-spatial-graph-pipeline/src/gpu_spatial_graph_pipeline/models/linear_ncem.py:116\u001b[0m, in \u001b[0;36mLinearNCEM.validation_step\u001b[0;34m(self, batch, _)\u001b[0m\n\u001b[1;32m    113\u001b[0m     batch \u001b[39m=\u001b[39m Batch\u001b[39m.\u001b[39mfrom_data_list(batch)\n\u001b[1;32m    114\u001b[0m mu, sigma \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(batch)\n\u001b[1;32m    115\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_module(\n\u001b[0;32m--> 116\u001b[0m     mu[: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size], batch\u001b[39m.\u001b[39my[: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size], sigma[: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    118\u001b[0m val_r2_score \u001b[39m=\u001b[39m r2_score(\n\u001b[1;32m    119\u001b[0m     batch\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mcpu()[: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size], mu\u001b[39m.\u001b[39mcpu()[: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\n\u001b[1;32m    122\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_r2_score\u001b[39m\u001b[39m\"\u001b[39m, val_r2_score, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    123\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.8/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearNCEM' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ad.concat(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59191    90de\n",
       "59192    90de\n",
       "59193    90de\n",
       "59194    90de\n",
       "59195    90de\n",
       "         ... \n",
       "18510    90de\n",
       "18511    90de\n",
       "18512    90de\n",
       "18513    90de\n",
       "18514    90de\n",
       "Name: donor, Length: 63747, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.obs.donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View of AnnData object with n_obs × n_vars = 18943 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n",
      "View of AnnData object with n_obs × n_vars = 22224 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n",
      "View of AnnData object with n_obs × n_vars = 5811 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n",
      "View of AnnData object with n_obs × n_vars = 16769 × 36\n",
      "    obs: 'point', 'cell_id', 'cell_size', 'donor', 'Cluster', 'Cluster_preprocessed'\n",
      "    obsm: 'spatial', 'node_types'\n"
     ]
    }
   ],
   "source": [
    "cats = x.obs.donor.unique()\n",
    "for cat in cats:\n",
    "    print(x[x.obs.donor == cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59191    90de\n",
       "59192    90de\n",
       "59193    90de\n",
       "59194    90de\n",
       "59195    90de\n",
       "         ... \n",
       "18510    90de\n",
       "18511    90de\n",
       "18512    90de\n",
       "18513    90de\n",
       "18514    90de\n",
       "Name: donor, Length: 63747, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.obs.donor.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pyg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "163d3d0f285585011c53b157ec761685e8fd2fea3691b3cdf426d39f7063e055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
