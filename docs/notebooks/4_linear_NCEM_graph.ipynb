{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear NCEM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import anndata as ad\n",
    "from geome import ann2data, transforms\n",
    "from utils.datasets import DatasetHartmann  # utils only for this example\n",
    "from utils.models.linear_ncem import LinearNCEM  # utils only for this example\n",
    "from utils import datamodule\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from raw files\n",
      "registering celldata\n",
      "collecting image-wise celldata\n",
      "adding graph-level covariates\n",
      "Loaded 58 images with complete data from 4 patients over 63747 cells with 36 cell features and 8 distinct celltypes.\n"
     ]
    }
   ],
   "source": [
    "fields = {\n",
    "    \"x\": [\"obs/Cluster_preprocessed\", \"obs/donor\", \"obsm/design_matrix\"],\n",
    "    \"y\": [\"X\"],\n",
    "}\n",
    "\n",
    "\n",
    "preprocess = transforms.Categorize(keys=[\"donor\", \"Cluster_preprocessed\", \"point\"], axis=\"obs\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.AddEdgeIndex(\n",
    "            edge_index_key=\"edge_index\",spatial_key=\"spatial\", key_added=\"spatial\", func_args={\"n_neighs\": 10}\n",
    "        ),\n",
    "        transforms.AddDesignMatrix(\n",
    "            \"obs/Cluster_preprocessed\",\n",
    "            \"obs/donor\",\n",
    "            \"obsp/spatial_distances\",\n",
    "            \"design_matrix\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "category_to_iterate = \"point\"\n",
    "\n",
    "\n",
    "a2d = ann2data.Ann2DataByCategory(\n",
    "    fields=fields,\n",
    "    category=category_to_iterate,\n",
    "    preprocess=preprocess,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Mibitof\n",
    "# supress the warning from the old dataset code\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    dataset = DatasetHartmann(data_path=\"./example_data/hartmann/\")\n",
    "    adatas = list(dataset.img_celldata.values())\n",
    "\n",
    "# Merge the list of adatas and convert some string to categories as they should be\n",
    "adata = ad.concat(adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[1338, 88], y=[1338, 36]),\n",
       " Data(x=[311, 88], y=[311, 36]),\n",
       " Data(x=[768, 88], y=[768, 36]),\n",
       " Data(x=[1020, 88], y=[1020, 36]),\n",
       " Data(x=[2100, 88], y=[2100, 36]),\n",
       " Data(x=[1325, 88], y=[1325, 36]),\n",
       " Data(x=[1091, 88], y=[1091, 36]),\n",
       " Data(x=[1046, 88], y=[1046, 36]),\n",
       " Data(x=[618, 88], y=[618, 36]),\n",
       " Data(x=[61, 88], y=[61, 36]),\n",
       " Data(x=[1316, 88], y=[1316, 36]),\n",
       " Data(x=[1540, 88], y=[1540, 36]),\n",
       " Data(x=[1822, 88], y=[1822, 36]),\n",
       " Data(x=[863, 88], y=[863, 36]),\n",
       " Data(x=[564, 88], y=[564, 36]),\n",
       " Data(x=[1023, 88], y=[1023, 36]),\n",
       " Data(x=[324, 88], y=[324, 36]),\n",
       " Data(x=[287, 88], y=[287, 36]),\n",
       " Data(x=[636, 88], y=[636, 36]),\n",
       " Data(x=[890, 88], y=[890, 36]),\n",
       " Data(x=[1235, 88], y=[1235, 36]),\n",
       " Data(x=[1020, 88], y=[1020, 36]),\n",
       " Data(x=[1241, 88], y=[1241, 36]),\n",
       " Data(x=[1438, 88], y=[1438, 36]),\n",
       " Data(x=[1021, 88], y=[1021, 36]),\n",
       " Data(x=[1632, 88], y=[1632, 36]),\n",
       " Data(x=[780, 88], y=[780, 36]),\n",
       " Data(x=[524, 88], y=[524, 36]),\n",
       " Data(x=[669, 88], y=[669, 36]),\n",
       " Data(x=[241, 88], y=[241, 36]),\n",
       " Data(x=[935, 88], y=[935, 36]),\n",
       " Data(x=[347, 88], y=[347, 36]),\n",
       " Data(x=[1499, 88], y=[1499, 36]),\n",
       " Data(x=[601, 88], y=[601, 36]),\n",
       " Data(x=[2268, 88], y=[2268, 36]),\n",
       " Data(x=[1912, 88], y=[1912, 36]),\n",
       " Data(x=[1678, 88], y=[1678, 36]),\n",
       " Data(x=[1025, 88], y=[1025, 36]),\n",
       " Data(x=[1306, 88], y=[1306, 36]),\n",
       " Data(x=[852, 88], y=[852, 36]),\n",
       " Data(x=[1664, 88], y=[1664, 36]),\n",
       " Data(x=[1698, 88], y=[1698, 36]),\n",
       " Data(x=[1672, 88], y=[1672, 36]),\n",
       " Data(x=[777, 88], y=[777, 36]),\n",
       " Data(x=[556, 88], y=[556, 36]),\n",
       " Data(x=[554, 88], y=[554, 36]),\n",
       " Data(x=[937, 88], y=[937, 36]),\n",
       " Data(x=[1524, 88], y=[1524, 36]),\n",
       " Data(x=[1528, 88], y=[1528, 36]),\n",
       " Data(x=[721, 88], y=[721, 36]),\n",
       " Data(x=[1395, 88], y=[1395, 36]),\n",
       " Data(x=[611, 88], y=[611, 36]),\n",
       " Data(x=[1872, 88], y=[1872, 36]),\n",
       " Data(x=[1217, 88], y=[1217, 36]),\n",
       " Data(x=[1531, 88], y=[1531, 36]),\n",
       " Data(x=[1927, 88], y=[1927, 36]),\n",
       " Data(x=[690, 88], y=[690, 36]),\n",
       " Data(x=[1706, 88], y=[1706, 36])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = list(a2d(adata))\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = datas[0].x.shape[1]\n",
    "out_channels = datas[0].y.shape[1]\n",
    "num_features, out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = datamodule.GraphAnnDataModule(datas=datas, num_workers=12, batch_size=12, learning_type=\"node\")\n",
    "model = LinearNCEM(in_channels=num_features, out_channels=out_channels, lr=0.0001, weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer: pl.Trainer = pl.Trainer(accelerator=\"gpu\" if torch.torch.cuda.is_available() else \"cpu\", max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "  | Name        | Type            | Params\n",
      "------------------------------------------------\n",
      "0 | model_sigma | Linear          | 3.2 K \n",
      "1 | model_mu    | Linear          | 3.2 K \n",
      "2 | loss_module | GaussianNLLLoss | 0     \n",
      "------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|█         | 485/4516 [00:08<01:07, 60.00it/s, v_num=17]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 266/266 [00:00<00:00, 421.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   -0.08943767845630646    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_r2_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -24.66176986694336     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  -0.08943767845630646   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_r2_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -24.66176986694336    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_r2_score': -24.66176986694336, 'test_loss': -0.08943767845630646}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "163d3d0f285585011c53b157ec761685e8fd2fea3691b3cdf426d39f7063e055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
