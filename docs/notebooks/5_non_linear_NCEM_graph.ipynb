{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear NCEM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import anndata as ad\n",
    "from geome import ann2data, transforms\n",
    "import warnings\n",
    "from utils.datasets import DatasetHartmann  # example dataset\n",
    "from utils.models.non_linear_ncem import NonLinearNCEM  # example model\n",
    "from utils import datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from raw files\n",
      "registering celldata\n",
      "collecting image-wise celldata\n",
      "adding graph-level covariates\n",
      "Loaded 58 images with complete data from 4 patients over 63747 cells with 36 cell features and 8 distinct celltypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Data(x=[1338, 12], edge_index=[2, 13380], y=[1338, 36]),\n",
       " Data(x=[311, 12], edge_index=[2, 3110], y=[311, 36]),\n",
       " Data(x=[768, 12], edge_index=[2, 7680], y=[768, 36]),\n",
       " Data(x=[1020, 12], edge_index=[2, 10200], y=[1020, 36]),\n",
       " Data(x=[2100, 12], edge_index=[2, 21000], y=[2100, 36]),\n",
       " Data(x=[1325, 12], edge_index=[2, 13250], y=[1325, 36]),\n",
       " Data(x=[1091, 12], edge_index=[2, 10910], y=[1091, 36]),\n",
       " Data(x=[1046, 12], edge_index=[2, 10460], y=[1046, 36]),\n",
       " Data(x=[618, 12], edge_index=[2, 6180], y=[618, 36]),\n",
       " Data(x=[61, 12], edge_index=[2, 610], y=[61, 36]),\n",
       " Data(x=[1316, 12], edge_index=[2, 13160], y=[1316, 36]),\n",
       " Data(x=[1540, 12], edge_index=[2, 15400], y=[1540, 36]),\n",
       " Data(x=[1822, 12], edge_index=[2, 18220], y=[1822, 36]),\n",
       " Data(x=[863, 12], edge_index=[2, 8630], y=[863, 36]),\n",
       " Data(x=[564, 12], edge_index=[2, 5640], y=[564, 36]),\n",
       " Data(x=[1023, 12], edge_index=[2, 10230], y=[1023, 36]),\n",
       " Data(x=[324, 12], edge_index=[2, 3240], y=[324, 36]),\n",
       " Data(x=[287, 12], edge_index=[2, 2870], y=[287, 36]),\n",
       " Data(x=[636, 12], edge_index=[2, 6360], y=[636, 36]),\n",
       " Data(x=[890, 12], edge_index=[2, 8900], y=[890, 36]),\n",
       " Data(x=[1235, 12], edge_index=[2, 12350], y=[1235, 36]),\n",
       " Data(x=[1020, 12], edge_index=[2, 10200], y=[1020, 36]),\n",
       " Data(x=[1241, 12], edge_index=[2, 12410], y=[1241, 36]),\n",
       " Data(x=[1438, 12], edge_index=[2, 14380], y=[1438, 36]),\n",
       " Data(x=[1021, 12], edge_index=[2, 10210], y=[1021, 36]),\n",
       " Data(x=[1632, 12], edge_index=[2, 16320], y=[1632, 36]),\n",
       " Data(x=[780, 12], edge_index=[2, 7800], y=[780, 36]),\n",
       " Data(x=[524, 12], edge_index=[2, 5240], y=[524, 36]),\n",
       " Data(x=[669, 12], edge_index=[2, 6690], y=[669, 36]),\n",
       " Data(x=[241, 12], edge_index=[2, 2410], y=[241, 36]),\n",
       " Data(x=[935, 12], edge_index=[2, 9350], y=[935, 36]),\n",
       " Data(x=[347, 12], edge_index=[2, 3470], y=[347, 36]),\n",
       " Data(x=[1499, 12], edge_index=[2, 14990], y=[1499, 36]),\n",
       " Data(x=[601, 12], edge_index=[2, 6010], y=[601, 36]),\n",
       " Data(x=[2268, 12], edge_index=[2, 22680], y=[2268, 36]),\n",
       " Data(x=[1912, 12], edge_index=[2, 19120], y=[1912, 36]),\n",
       " Data(x=[1678, 12], edge_index=[2, 16780], y=[1678, 36]),\n",
       " Data(x=[1025, 12], edge_index=[2, 10250], y=[1025, 36]),\n",
       " Data(x=[1306, 12], edge_index=[2, 13060], y=[1306, 36]),\n",
       " Data(x=[852, 12], edge_index=[2, 8520], y=[852, 36]),\n",
       " Data(x=[1664, 12], edge_index=[2, 16640], y=[1664, 36]),\n",
       " Data(x=[1698, 12], edge_index=[2, 16980], y=[1698, 36]),\n",
       " Data(x=[1672, 12], edge_index=[2, 16720], y=[1672, 36]),\n",
       " Data(x=[777, 12], edge_index=[2, 7770], y=[777, 36]),\n",
       " Data(x=[556, 12], edge_index=[2, 5560], y=[556, 36]),\n",
       " Data(x=[554, 12], edge_index=[2, 5540], y=[554, 36]),\n",
       " Data(x=[937, 12], edge_index=[2, 9370], y=[937, 36]),\n",
       " Data(x=[1524, 12], edge_index=[2, 15240], y=[1524, 36]),\n",
       " Data(x=[1528, 12], edge_index=[2, 15280], y=[1528, 36]),\n",
       " Data(x=[721, 12], edge_index=[2, 7210], y=[721, 36]),\n",
       " Data(x=[1395, 12], edge_index=[2, 13950], y=[1395, 36]),\n",
       " Data(x=[611, 12], edge_index=[2, 6110], y=[611, 36]),\n",
       " Data(x=[1872, 12], edge_index=[2, 18720], y=[1872, 36]),\n",
       " Data(x=[1217, 12], edge_index=[2, 12170], y=[1217, 36]),\n",
       " Data(x=[1531, 12], edge_index=[2, 15310], y=[1531, 36]),\n",
       " Data(x=[1927, 12], edge_index=[2, 19270], y=[1927, 36]),\n",
       " Data(x=[690, 12], edge_index=[2, 6900], y=[690, 36]),\n",
       " Data(x=[1706, 12], edge_index=[2, 17060], y=[1706, 36])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = {\n",
    "    \"x\": [\"obs/Cluster_preprocessed\", \"obs/donor\"],\n",
    "    \"edge_index\": [\"uns/edge_index\"],\n",
    "    \"y\": [\"X\"],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "preprocess = transforms.Categorize([\"donor\", \"Cluster_preprocessed\", \"point\"], axis=\"obs\")\n",
    "transform = transforms.AddEdgeIndex(\n",
    "    edge_index_key=\"edge_index\",\n",
    "    spatial_key=\"spatial\",\n",
    "    key_added=\"spatial\",\n",
    "    func_args={\"n_neighs\": 10},\n",
    ")\n",
    "\n",
    "\n",
    "category_to_iterate = \"point\"\n",
    "\n",
    "a2d = ann2data.Ann2DataByCategory(\n",
    "    fields=fields,\n",
    "    category=category_to_iterate,\n",
    "    preprocess=preprocess,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "\n",
    "# Mibitof\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    dataset = DatasetHartmann(data_path=\"./example_data/hartmann/\")\n",
    "    adatas = list(dataset.img_celldata.values())\n",
    "\n",
    "# Merge the list of adatas and convert some string to categories as they should be\n",
    "adata = ad.concat(adatas)\n",
    "\n",
    "datas = list(a2d(adata))\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = datas[0].x.shape[1]\n",
    "out_channels = datas[0].y.shape[1]\n",
    "num_features, out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = datamodule.GraphAnnDataModule(datas=datas, num_workers=12, batch_size=100, learning_type=\"node\")\n",
    "model = NonLinearNCEM(\n",
    "    in_channels=num_features,\n",
    "    out_channels=out_channels,\n",
    "    encoder_hidden_dims=[16],\n",
    "    decoder_hidden_dims=[16],\n",
    "    latent_dim=14,\n",
    "    lr=0.001,\n",
    "    weight_decay=0.00001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer: pl.Trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.torch.cuda.is_available() else \"cpu\", max_epochs=100, log_every_n_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "  | Name          | Type            | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder       | GNNModel        | 446   \n",
      "1 | decoder_sigma | MLPModel        | 852   \n",
      "2 | decoder_mu    | MLPModel        | 852   \n",
      "3 | loss_module   | GaussianNLLLoss | 0     \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/542 [00:00<?, ?it/s, v_num=16, val_r2_score=-7.78, val_loss=75.20]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  83%|████████▎ | 449/542 [00:11<00:02, 40.17it/s, v_num=16, val_r2_score=-7.78, val_loss=75.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/geome/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 220.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    42.403907775878906     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_r2_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -8.196203231811523     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   42.403907775878906    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_r2_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -8.196203231811523    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_r2_score': -8.196203231811523, 'test_loss': 42.403907775878906}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
